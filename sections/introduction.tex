\chapter{Introduction}

Cardiovascular diseases (CVDs) remain the leading cause of illness and death globally, with the burden falling especially hard on people in low- and middle-income countries. In many of these settings, access to advanced diagnostic tools like ECGs and cardiac imaging is limited \cite{roth2020global}. In contrast, listening to heart sounds—a method known as auscultation—offers a non-invasive, affordable, and widely accessible way to detect heart conditions such as valve disorders, coronary artery disease, and arrhythmias \cite{li2020review, roy2019heart}.

Thanks to recent advances in artificial intelligence (AI) and the growing ecosystem of the Internet of Health Things (IoHT), it’s now possible to automate and remotely monitor these heart sounds. This development opens the door to early diagnosis and continuous care, even in remote or resource-limited clinics \cite{winther2021advanced, qian2019deep}. However, most existing AI models rely on centralized data collection, which poses serious privacy risks and faces ethical and legal constraints, especially under regulations like HIPAA \cite{swarup2018digital}. This makes many hospitals hesitant to share sensitive patient data.

Federated Learning (FL) offers a promising alternative. It allows institutions to collaboratively train models without ever exchanging raw data \cite{xu2021federated}. Still, traditional FL methods often assume all participants use the same model types and share the same label distributions—an assumption that doesn’t reflect reality. Clinics may only have access to a narrow slice of heart sound data and might use different machine learning tools based on their resources \cite{qian2021artificial,qian2021can}.

To tackle these limitations, we introduce \textbf{MStacking}—a federated learning framework that supports heterogeneous models and learns from partially labeled datasets. It uses a stacking ensemble method to merge insights from each client’s locally trained model, combining both raw acoustic features and time–frequency images like PCG spectrograms. MStacking aims to make AI-assisted auscultation truly practical and inclusive, supporting scalable and privacy-preserving diagnostics across diverse medical environments \cite{xu2021federated}.
